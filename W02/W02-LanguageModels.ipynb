{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "486bac8c",
   "metadata": {},
   "source": [
    "(W01 là giới thiệu môn học)\n",
    "\n",
    "# Giới thiệu n-gram\n",
    "\n",
    "Cho 1 câu $W$ gồm $n$ từ: $w_1, w_2, .., w_n$.\n",
    "\n",
    "- Xác suất 1 câu (1 chuỗi từ): $P(W) = P(w_1, w_2, .., w_n)$\n",
    "- Xác suất từ tiếp theo trong 1 câu (1 chuỗi từ), cho trước $n - 1$ từ trước đó: $P(w_n | w_1, w_2, .., w_{n - 1})$\n",
    "\n",
    "Mô hình $P(W)$ hay $P(w_n | w_1, w_2, .., w_{n - 1})$ gọi là **Mô hình ngôn ngữ**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca596e1f",
   "metadata": {},
   "source": [
    "### Chain rule:\n",
    "- 2 biến: $P(x_1, x_2) = P(x_1)P(x_2 | x_1)$\n",
    "- 3 biến: $P(x_1, x_2, x_3) = P(x_1)P(x_2 | x_1)P(x_3 | x_1x_2)$\n",
    "- 4 biến: $P(x_1, x_2, x_3, x_4) = P(x_1)P(x_2 | x_1)P(x_3 | x_1x_2)P(x_4 | x_1x_2x_3)$\n",
    "- $n$ biến: $P(x_1, x_2, .., x_n) = P(x_1)P(x_2 | x_1) .. P(x_n | x_1 .. x_{n - 1})$\n",
    "\n",
    "Nhận xét: câu càng dài thì số phép tính càng nhiều, vậy cần có cách pre-calculate và chỉ tái sử dụng các giá trị đã tính toán."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a72359",
   "metadata": {},
   "source": [
    "Viết lại chain rule dưới dạng công thức toán:\n",
    "\n",
    "$\\displaystyle P(w_1w_2..w_n) = \\prod_{i} P(w_i | w_1w_2..w_{n - 1})$\n",
    "\n",
    "Ví dụ: $P(\\text{ngôn ngữ tự nhiên}) = P(\\text{ngôn})P(\\text{ngữ} | \\text{ngôn})P(\\text{tự} | \\text{ngôn ngữ}) P(\\text{nhiên} | \\text{ngôn ngữ tự})$\n",
    "\n",
    "Một ước lượng đơn giản: $P(w) = \\frac{\\text{count}(w)}{|W|}$. Khi đó:\n",
    "- $ P(\\text{ngôn}) = \\frac{\\text{count}(\\text{ngôn})}{|\\text{ngôn ngữ tự nhiên}|} = \\frac{1}{4}$\n",
    "- $ P(\\text{ngôn} | \\text{ngữ}) = \\frac{\\text{count}(\\text{ngôn})}{\\text{count}(\\text{ngữ})} = 1$\n",
    "- .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117d7b2b",
   "metadata": {},
   "source": [
    "### Giả thuyết Markov\n",
    "- $P(\\text{nhiên} | \\text{ngôn ngữ tự}) \\approx P(\\text{nhiên} | \\text{tự}), n = 2$ hoặc\n",
    "- $P(\\text{nhiên} | \\text{ngôn ngữ tự}) \\approx P(\\text{nhiên} | \\text{ngữ tự}), n = 3$\n",
    "\n",
    "Tổng quát:\n",
    "- $\\displaystyle P(w_1w_2..w_n) \\approx \\prod_{i} P(w_i | w_{i - k}..w_{i - 1})$\n",
    "- $P(w_i | w_1w_2..w_{i - 1}) \\approx P(w_i | w_{i - k}..w_{i - 1})$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1497fe",
   "metadata": {},
   "source": [
    "## n-gram\n",
    "- Mô hình unigram (1-gram): $\\displaystyle P(w_1w_2..w_n) \\approx \\prod_{i} P(w_i)$. Nhận xét: từ có xác suất cao là lấy, không có phụ thuộc từ đứng trước.\n",
    "- Mô hình bigram (2-gram): $\\displaystyle P(w_i | w_1w_2..w_{i - 1}) \\approx \\prod_{i} P(w_i | w_{i - 1})$. Nhận xét: từ có xác suất cao là lấy, không có phụ thuộc từ đứng trước.\n",
    "- Mở rộng: trigram, 4-gram, 5-gram, ..etc\n",
    "\n",
    "Nhận xét:\n",
    "- Ảnh hưởng của phụ thuộc xa (long-distance dependency).\n",
    "- Hoạt động tốt trong đa số trường hợp.\n",
    "- $n$ càng lớn thì số phép tính càng lớn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2dc4e9",
   "metadata": {},
   "source": [
    "### Ví dụ:\n",
    "Cho trước bộ ngữ liệu huấn luyện thành mô hình ngôn ngữ (LM): $V = w_1, w_2, w_3, .., w_{10}$.\n",
    "\n",
    "LM (unigram) sau khi huấn luyện:\n",
    "- $P(w_1) = 0.01$\n",
    "- $P(w_2) = 0.002$\n",
    "- $P(w_3) = 0.2$\n",
    "- $P(w_4) = 0.6$\n",
    "- $P(w_5) = 0.15$\n",
    "- ..\n",
    "- $P(w_{10}) = 0.09$\n",
    "\n",
    "Trong quá trình predict/test: \n",
    "- $P(w_1w_3w_5) = P(w_1)P(w_3)P(w_5) = 0.01\\times 0.2\\times 0.15 = 0.0003$\n",
    "- $P(w_5w_{10}) = P(w_5)P(w_{10}) = 0.2\\times 0.09 = 0.018$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5007dad4",
   "metadata": {},
   "source": [
    "## Ước lượng xác suất n-gram\n",
    "### Ước lượng khả năng cực đại (Maximum Likelihood Estimation)\n",
    "- $P(w_i | w_{i - 1}) = \\frac{\\text{count}(w_{i - 1}, w_i)}{\\text{count}(w_{i - 1})}$ (số lần 2 cụm $i, i - 1$ đi chung / số lần kí tự $i - 1$ đi 1 mình)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48a9272",
   "metadata": {},
   "source": [
    "Vấn đề với phép nhân:\n",
    "- Underflow\n",
    "- Tốc độ chậm\n",
    "\n",
    "Chuyển sang phép cộng:\n",
    "- $\\log(p_1p_2..p_n) = \\log(p_1) + \\log(p_2) + .. + \\log(p_n)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9590e048",
   "metadata": {},
   "source": [
    "## Đánh giá mô hình\n",
    "- Mô hình ngôn ngữ: xác suất cao với câu \"hay gặp\" so với các câu \"hiếm gặp\"\n",
    "- Huấn luyện tham số trên training set\n",
    "- Kiểm tra trên unseen set (khác với tập train, có độ đo đánh giá).\n",
    "\n",
    "- Đánh giá ngoại tại (extrinsic): so sánh 2 mô hình -> đánh giá hoàn hảo, nhưng mất thời gian\n",
    "    - Đặt vào tác vụ\n",
    "    - Chạy tác vụ, đánh giá accuracy của A và B\n",
    "    - So sánh accuracy giữa A và B\n",
    "- Đánh giá nội tại (intrinsic): perplexity\n",
    "    - Xấp xỉ không tốt\n",
    "    - Hữu dụng khi đánh giá thực nghiệm (pilot experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc82dfd",
   "metadata": {},
   "source": [
    "- Perplexity:\n",
    "    - Đánh giá khả năng đoán từ kế tiếp\n",
    "    - Xác suất đảo của tập kiểm tra => perplexity thấp thì chất lượng càng tốt\n",
    "- Mô hình tốt là mô hình có xác suất cao hơn đối với từ **thật sự** xuất hiện.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18610417",
   "metadata": {},
   "source": [
    "# Các phương pháp làm mịn\n",
    "Xuất hiện cụm từ không có trong corpus => $P = 0$, không thể chia để lấy perplexity.\n",
    "\n",
    "- Phương pháp Thêm-1 (Laplace):\n",
    "    - Giả sử thấy mỗi từ thêm 1 lần.\n",
    "    - Cộng 1 vào tất cả phép đếm: $P(w_i | w_{i - 1}) = \\frac{c(w_{i - 1}, w_i)}{c(w_{i - 1})}$ biến thành $P^{*}(w_i | w_{i - 1}) = \\frac{c(w_{i - 1}, w_i) + 1}{c(w_{i - 1}) + V}$ ($V$ là tổng số bigram)\n",
    "- Nội suy\n",
    "- Quay lui\n",
    "- Good Turing\n",
    "- Kneser-Ney\n",
    "- .."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
